{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from functools import cache\n",
    "from pathlib import Path\n",
    "from typing import Any\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "from loguru import logger\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import DataStructs, rdMolDescriptors\n",
    "from rdkit.Chem.GraphDescriptors import BertzCT\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_json_files(folder_path: str) -> Any:\n",
    "    folder_full_path = f\"{folder_path}\"\n",
    "    folder = Path(folder_full_path)\n",
    "    json_files = folder.rglob(\"*.json\")\n",
    "    results = []\n",
    "\n",
    "    for json_file_path in json_files:\n",
    "        with Path(json_file_path).open(\"r\") as f:\n",
    "            results.append(json.load(f))\n",
    "    json_file_ids = [file.stem for file in list(folder.rglob(\"*.json\"))]\n",
    "    return results, json_file_ids\n",
    "\n",
    "\n",
    "@cache\n",
    "def compute_fingerprint(smiles):\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    return Chem.RDKFingerprint(mol, maxPath=8, fpSize=2048)\n",
    "\n",
    "\n",
    "@cache\n",
    "def tanimoto_similarity(smiles1, smiles2):\n",
    "    fp1 = compute_fingerprint(smiles1)\n",
    "    fp2 = compute_fingerprint(smiles2)\n",
    "    return DataStructs.FingerprintSimilarity(fp1, fp2, metric=DataStructs.TanimotoSimilarity)\n",
    "\n",
    "\n",
    "@cache\n",
    "def compute_molecular_formula(smiles):\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    return rdMolDescriptors.CalcMolFormula(mol)\n",
    "\n",
    "\n",
    "def filter_by_molecular_formula(results: list, molecular_formula: str):\n",
    "    filtered_results = []\n",
    "    for result in results:\n",
    "        if compute_molecular_formula(result) == molecular_formula:\n",
    "            filtered_results.append(result)\n",
    "    return filtered_results\n",
    "\n",
    "\n",
    "def filter_final_population(full_results: dict):\n",
    "    all_smiles_in_final_population = [*full_results[\"final_population\"]]\n",
    "    original_smiles_molecular_formula = compute_molecular_formula(full_results[\"original_smiles\"])\n",
    "    return filter_by_molecular_formula(all_smiles_in_final_population, original_smiles_molecular_formula)\n",
    "\n",
    "\n",
    "# max tanimoto initial population\n",
    "def compute_max_tanimoto_initial_population(full_results: dict):\n",
    "    original_smiles = get_original_smiles(full_results)\n",
    "    initial_population = full_results[\"initial_population\"][:20]\n",
    "    tanimoto_similarities = []\n",
    "    for smiles in initial_population:\n",
    "        tanimoto_similarities.append(tanimoto_similarity(original_smiles, smiles))\n",
    "    return max(tanimoto_similarities)\n",
    "\n",
    "\n",
    "def get_original_smiles(full_results: dict):\n",
    "    return full_results[\"original_smiles\"]\n",
    "\n",
    "\n",
    "@cache\n",
    "def compute_molecule_size(smiles):\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    return mol.GetNumAtoms()\n",
    "\n",
    "\n",
    "@cache\n",
    "def compute_molecular_complexity(smiles):\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    return BertzCT(mol)\n",
    "\n",
    "\n",
    "def compute_results(full_results: dict):\n",
    "    original_smiles = get_original_smiles(full_results)\n",
    "    filtered_results = filter_final_population(full_results)\n",
    "\n",
    "    tanimoto_similarities = []\n",
    "    for result in filtered_results:\n",
    "        tanimoto_similarities.append(tanimoto_similarity(original_smiles, result))\n",
    "\n",
    "    if not tanimoto_similarities:\n",
    "        return {\n",
    "            \"1\": False,\n",
    "            \"5\": False,\n",
    "            \"10\": False,\n",
    "            \"max\": 0,\n",
    "            \"best_score\": 0,\n",
    "            \"mol_size\": compute_molecule_size(original_smiles),\n",
    "        }\n",
    "    return {\n",
    "        \"1\": tanimoto_similarities[0] == 1,\n",
    "        \"5\": 1 in tanimoto_similarities[:5],\n",
    "        \"10\": 1 in tanimoto_similarities[:10],\n",
    "        \"Found\": 1 in tanimoto_similarities,\n",
    "        \"max\": tanimoto_similarities[0],\n",
    "        \"best_score\": full_results[\"final_population\"][filtered_results[0]],\n",
    "        \"mol_size\": compute_molecule_size(original_smiles),\n",
    "        \"max_initial_population\": compute_max_tanimoto_initial_population(full_results),\n",
    "        \"molecular_complexity\": compute_molecular_complexity(original_smiles),\n",
    "    }\n",
    "\n",
    "\n",
    "def stats_save(seed, folder_path):\n",
    "    ex, ids = read_json_files(folder_path, seed)\n",
    "    stats = {}\n",
    "    for i, result in enumerate(tqdm(ex)):\n",
    "        stats[int(ids[i])] = compute_results(result)\n",
    "\n",
    "    data_as_df = pd.DataFrame(stats).T.sort_index()\n",
    "    data_as_df.index.name = \"molecule_id\"\n",
    "    data_as_df.to_csv(f\"results_{seed}.csv\")\n",
    "    # logger.info(f\"Saved stats for seed {seed}\")\n",
    "    stats = data_as_df.mean()\n",
    "    # logger.info(f\"Mean stats for seed {seed}: <br>{stats}\")\n",
    "    # logger.info(f\"{len(data_as_df)} molecules in seed {seed}\")\n",
    "    return data_as_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def merge_json_values(file_paths: list[str]) -> dict[str, list[Any]]:\n",
    "    \"\"\"\n",
    "    Reads multiple JSON files and combines values for matching keys.\n",
    "\n",
    "    Args:\n",
    "        file_paths (List[str]): List of paths to JSON files\n",
    "\n",
    "    Returns:\n",
    "        Dict[str, List[Any]]: Dictionary where each key maps to a list of values from all files\n",
    "    \"\"\"\n",
    "    # try:\n",
    "    # Initialize result dictionary\n",
    "    combined_data: dict[str, list[Any]] = {}\n",
    "\n",
    "    # Process each file\n",
    "    for file_path in file_paths:\n",
    "        with Path(file_path).open(\"r\") as f:\n",
    "            data = json.load(f)\n",
    "\n",
    "            # For first file, initialize lists for each key\n",
    "            if not combined_data:\n",
    "                combined_data = {key: [value] for key, value in data.items()}\n",
    "            else:\n",
    "                # Verify keys match\n",
    "                if set(data.keys()) != set(combined_data.keys()):\n",
    "                    raise ValueError(f\"Keys in {file_path} don't match the keys in other files\")\n",
    "\n",
    "                # Append values to existing lists\n",
    "                for key, value in data.items():\n",
    "                    combined_data[key].append(value)\n",
    "    # combined_data[\"final_population\"] = [{smiles:score}, {smiles:score}, ...]\n",
    "    # list of keys\n",
    "    list_of_keys_final_population = [list(d.keys()) for d in combined_data[\"final_population\"]]\n",
    "    list_of_keys_final_population = [item for sublist in list_of_keys_final_population for item in sublist]\n",
    "    list_of_values_final_population = [list(d.values()) for d in combined_data[\"final_population\"]]\n",
    "    list_of_values_final_population = [item for sublist in list_of_values_final_population for item in sublist]\n",
    "    dataframe = pd.DataFrame({\"smiles\": list_of_keys_final_population, \"score\": list_of_values_final_population})\n",
    "    # dataframe.to_csv(\"temp.csv\")\n",
    "    # only unique smiles and highest score\n",
    "    dataframe = dataframe.groupby(\"smiles\").max().reset_index()\n",
    "    # combined_data[\"final_population\"] = dict(ChainMap(*combined_data[\"final_population\"]))\n",
    "    combined_data[\"final_population\"] = dict(zip(dataframe[\"smiles\"], dataframe[\"score\"]))\n",
    "    # final_population sorted by score final_population: {smiles: score}\n",
    "    combined_data[\"final_population\"] = dict(sorted(combined_data[\"final_population\"].items(), key=lambda x: x[1], reverse=True))\n",
    "    combined_data[\"initial_population\"] = combined_data[\"initial_population\"][0]\n",
    "    combined_data[\"best_score\"] = combined_data[\"final_population\"][list(combined_data[\"final_population\"].keys())[0]]\n",
    "    combined_data[\"original_smiles\"] = combined_data[\"original_smiles\"][0]\n",
    "    combined_data[\"tanimoto_similarity\"] = tanimoto_similarity(\n",
    "        combined_data[\"original_smiles\"], list(combined_data[\"final_population\"].keys())[0]\n",
    "    )\n",
    "    combined_data[\"best_individual\"] = list(combined_data[\"final_population\"].keys())[0]\n",
    "    return combined_data\n",
    "\n",
    "\n",
    "def save_combined_json(combined_data: dict[str, list[Any]], output_path: str) -> None:\n",
    "    \"\"\"\n",
    "    Saves the combined data to a JSON file.\n",
    "\n",
    "    Args:\n",
    "        combined_data (Dict[str, List[Any]]): Combined data to save\n",
    "        output_path (str): Path where to save the combined JSON\n",
    "    \"\"\"\n",
    "    with Path(output_path).open(\"w\") as f:\n",
    "        json.dump(combined_data, f, indent=2)\n",
    "\n",
    "\n",
    "def json_files(parent_folder_pattern: str, range_number: int = 1001) -> None:\n",
    "    from glob import glob\n",
    "\n",
    "    for i in range(range_number):\n",
    "        try:\n",
    "            files = glob(f\"{parent_folder_pattern}*/{i}.json\")\n",
    "            # files = [file for file in files if \"seed_1000\" not in file]\n",
    "            # Combine the data\n",
    "            result = merge_json_values(files)\n",
    "            if result:\n",
    "                # Optionally save to a new JSON file\n",
    "                save_combined_json(result, f\"{parent_folder_pattern}/{i}.json\")\n",
    "        except Exception as e:\n",
    "            print(i)\n",
    "            continue\n",
    "\n",
    "\n",
    "json_files(\"final_results_graphga\", 1001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'1'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 45\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m overall_top_1, overall_top_5, overall_top_10, overall_top_50\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m# for i in [555, 333, 222, 888]:\u001b[39;00m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m#     top_1, top_5, top_10, top_50 = count_scores([i])\u001b[39;00m\n\u001b[0;32m---> 45\u001b[0m top_overall_1, top_overall_5, top_overall_10, top_overall_50 \u001b[38;5;241m=\u001b[39m \u001b[43mcount_scores\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfinal_results_graphga\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTop 1 overall: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtop_overall_1\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     47\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTop 5 overall: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtop_overall_5\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[21], line 27\u001b[0m, in \u001b[0;36mcount_scores\u001b[0;34m(seeds, folder_path)\u001b[0m\n\u001b[1;32m     25\u001b[0m len_seed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(stats)\n\u001b[1;32m     26\u001b[0m all_stats\u001b[38;5;241m.\u001b[39mappend(stats)\n\u001b[0;32m---> 27\u001b[0m top_1 \u001b[38;5;241m=\u001b[39m \u001b[43mcount_correct_seed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstats\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m top_5 \u001b[38;5;241m=\u001b[39m count_correct_seed(stats, \u001b[38;5;241m5\u001b[39m)\n\u001b[1;32m     29\u001b[0m top_10 \u001b[38;5;241m=\u001b[39m count_correct_seed(stats, \u001b[38;5;241m10\u001b[39m)\n",
      "Cell \u001b[0;32mIn[21], line 2\u001b[0m, in \u001b[0;36mcount_correct_seed\u001b[0;34m(stats, top_n)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcount_correct_seed\u001b[39m(stats, top_n\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m----> 2\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m stats[\u001b[43mstats\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mtop_n\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__len__\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda/envs/chembench/lib/python3.12/site-packages/pandas/core/frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/miniconda/envs/chembench/lib/python3.12/site-packages/pandas/core/indexes/range.py:417\u001b[0m, in \u001b[0;36mRangeIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    415\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m    416\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Hashable):\n\u001b[0;32m--> 417\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n\u001b[1;32m    418\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n\u001b[1;32m    419\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: '1'"
     ]
    }
   ],
   "source": [
    "def count_correct_seed(stats, top_n=1):\n",
    "    return stats[stats[f\"{top_n}\"] == 1].__len__()\n",
    "\n",
    "\n",
    "def check_no_true_duplicates(all_stats: list):\n",
    "    # concatenate all dataframes\n",
    "    all_stats = pd.concat(all_stats)\n",
    "    all_stats.reset_index(inplace=True)\n",
    "    # keep the duplicate with the highest score\n",
    "    all_stats = (\n",
    "        all_stats.sort_values(\"best_score\", ascending=False)\n",
    "        .drop_duplicates(\"molecule_id\")\n",
    "        .sort_values(\"molecule_id\")\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "    all_stats.to_csv(\"all_stats.csv\")\n",
    "    return True\n",
    "\n",
    "\n",
    "def count_scores(seeds: list[int], folder_path=\"final_results_graphga\") -> tuple:\n",
    "    top_1_seeds, top_5_seeds, top_10_seeds, top_50_seeds = [], [], [], []\n",
    "    all_stats = []\n",
    "    for seed in seeds:\n",
    "        stats = stats_save(seed, folder_path)\n",
    "        len_seed = len(stats)\n",
    "        all_stats.append(stats)\n",
    "        top_1 = count_correct_seed(stats, 1)\n",
    "        top_5 = count_correct_seed(stats, 5)\n",
    "        top_10 = count_correct_seed(stats, 10)\n",
    "        top_50 = count_correct_seed(stats, \"Found\")\n",
    "        top_1_seeds.append(top_1)\n",
    "        top_5_seeds.append(top_5)\n",
    "        top_10_seeds.append(top_10)\n",
    "        top_50_seeds.append(top_50)\n",
    "    check_no_true_duplicates(all_stats)\n",
    "    overall_top_1 = sum(top_1_seeds) / len_seed\n",
    "    overall_top_5 = sum(top_5_seeds) / len_seed\n",
    "    overall_top_10 = sum(top_10_seeds) / len_seed\n",
    "    overall_top_50 = sum(top_50_seeds) / len_seed\n",
    "    return overall_top_1, overall_top_5, overall_top_10, overall_top_50\n",
    "\n",
    "\n",
    "# for i in [555, 333, 222, 888]:\n",
    "#     top_1, top_5, top_10, top_50 = count_scores([i])\n",
    "top_overall_1, top_overall_5, top_overall_10, top_overall_50 = count_scores([1000], \"final_results_graphga\")\n",
    "logger.info(f\"Top 1 overall: {top_overall_1}\")\n",
    "logger.info(f\"Top 5 overall: {top_overall_5}\")\n",
    "logger.info(f\"Top 10 overall: {top_overall_10}\")\n",
    "logger.info(f\"Percentage found: {top_overall_50}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'top_overall_1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 133\u001b[0m\n\u001b[1;32m    129\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fig\n\u001b[1;32m    132\u001b[0m \u001b[38;5;66;03m# Usage:\u001b[39;00m\n\u001b[0;32m--> 133\u001b[0m fig \u001b[38;5;241m=\u001b[39m create_barchart(\u001b[43mtop_overall_1\u001b[49m, top_overall_5, top_overall_10, top_overall_50)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'top_overall_1' is not defined"
     ]
    }
   ],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "\n",
    "def create_barchart(top_1, top_5, top_10, top_50):\n",
    "    best_literature_top_1, best_literature_top_5, best_literature_top_10 = 0.6699, 0.8409, 0.8650\n",
    "    dataframe_plot = pd.DataFrame(\n",
    "        {\n",
    "            \"Metric\": [\n",
    "                \"ref. top 1\",\n",
    "                \"top 1\",\n",
    "                \"ref. top 5\",\n",
    "                \"top 5\",\n",
    "                \"in the population\",\n",
    "            ],\n",
    "            \"Value\": [best_literature_top_1, top_1, best_literature_top_5, top_5, top_50],\n",
    "        }\n",
    "    )\n",
    "\n",
    "    custom_colors = {\n",
    "        \"ref. top 1\": \"rgba(152, 86, 86, 0.3)\",\n",
    "        \"top 1\": \"rgba(152, 86, 86, 0.7)\",\n",
    "        \"ref. top 5\": \"rgba(86, 86, 152, 0.3)\",\n",
    "        \"top 5\": \"rgba(86, 86, 152, 0.7)\",\n",
    "        \"in the population\": \"rgba(86, 86, 86, 0.7)\",\n",
    "    }\n",
    "\n",
    "    # Create figure\n",
    "    fig = go.Figure()\n",
    "\n",
    "    # Add bars\n",
    "    for metric in dataframe_plot[\"Metric\"]:\n",
    "        fig.add_trace(\n",
    "            go.Bar(\n",
    "                x=[dataframe_plot[dataframe_plot[\"Metric\"] == metric][\"Value\"].iloc[0]],\n",
    "                y=[metric],\n",
    "                orientation=\"h\",\n",
    "                marker_color=custom_colors[metric],\n",
    "                width=0.6,\n",
    "                showlegend=False,\n",
    "            )\n",
    "        )\n",
    "\n",
    "    # Update layout\n",
    "    sizing = 305\n",
    "    fig.update_layout(\n",
    "        template=\"plotly_white\",\n",
    "        width=sizing * 1.618,\n",
    "        height=sizing,\n",
    "        margin={\"l\": 40, \"r\": 20, \"t\": 20, \"b\": 40},\n",
    "        plot_bgcolor=\"white\",\n",
    "        font={\"color\": \"rgb(120, 120, 120)\"},\n",
    "        bargap=0.15,\n",
    "        bargroupgap=0.03,\n",
    "        shapes=[\n",
    "            # Add x-axis line\n",
    "            {\n",
    "                \"type\": \"line\",\n",
    "                \"xref\": \"paper\",\n",
    "                \"yref\": \"y\",\n",
    "                \"x0\": 0,\n",
    "                \"x1\": 1,\n",
    "                \"y0\": -0.5,\n",
    "                \"y1\": -0.5,  # Position below the bottom bar\n",
    "                \"line\": {\"color\": \"rgb(120, 120, 120)\", \"width\": 1},\n",
    "            },\n",
    "            # Add y-axis line\n",
    "            {\n",
    "                \"type\": \"line\",\n",
    "                \"xref\": \"x\",\n",
    "                \"yref\": \"paper\",\n",
    "                \"x0\": 0,\n",
    "                \"y0\": 0,\n",
    "                \"x1\": 0,\n",
    "                \"y1\": 1,\n",
    "                \"line\": {\"color\": \"rgb(120, 120, 120)\", \"width\": 1},\n",
    "            },\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    # Update x-axis\n",
    "    fig.update_xaxes(\n",
    "        title_text=\"fraction of correct predictions\",\n",
    "        range=[-0.0, 1.02],  # Add padding\n",
    "        showgrid=False,\n",
    "        zeroline=False,\n",
    "        showline=False,\n",
    "        ticks=\"outside\",\n",
    "        tickwidth=1,\n",
    "        tickcolor=\"rgb(120, 120, 120)\",\n",
    "        ticklen=5,\n",
    "        tickvals=np.arange(0, 1.2, 0.2),\n",
    "        tickformat=\".1f\",\n",
    "    )\n",
    "\n",
    "    # Update y-axis\n",
    "    fig.update_yaxes(\n",
    "        title_text=\"metric\",\n",
    "        showgrid=True,\n",
    "        gridwidth=1,\n",
    "        gridcolor=\"rgba(173, 216, 230, 0.3)\",\n",
    "        zeroline=False,\n",
    "        showline=False,\n",
    "        ticks=\"outside\",\n",
    "        tickwidth=1,\n",
    "        tickcolor=\"rgb(120, 120, 120)\",\n",
    "        ticklen=5,\n",
    "    )\n",
    "\n",
    "    # Add reference line for perfect score\n",
    "    fig.add_vline(\n",
    "        x=1,\n",
    "        line_dash=\"dot\",\n",
    "        line_color=\"rgb(120, 120, 120)\",\n",
    "        annotation={\n",
    "            \"text\": \"perfect score\",\n",
    "            \"textangle\": 90,\n",
    "            \"x\": 1.01,\n",
    "            \"yref\": \"paper\",\n",
    "            \"y\": 0.7,\n",
    "            \"showarrow\": False,\n",
    "            \"font\": {\"color\": \"rgb(120, 120, 120)\"},\n",
    "        },\n",
    "    )\n",
    "    # remove grid\n",
    "    fig.update_xaxes(showgrid=False)\n",
    "    fig.update_yaxes(showgrid=False)\n",
    "    fig.write_image(\"figures/barchart.pdf\", scale=2)\n",
    "    fig.show()\n",
    "    return fig\n",
    "\n",
    "\n",
    "# Usage:\n",
    "fig = create_barchart(top_overall_1, top_overall_5, top_overall_10, top_overall_50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_distr_of_scores_when_correct_vs_not_correct(prop_to_plot, color_column, stat=None):\n",
    "    stats = pd.read_csv(\"results_1000.csv\")\n",
    "    stats = stats[stats[\"best_score\"] != 0]\n",
    "\n",
    "    # bin mol sizes each 5\n",
    "    # mol_size = stats[\"mol_size\"]\n",
    "    # rename 50 to Top 50\n",
    "    stats = stats.rename(columns={\"5\": \"Top 5\", \"10\": \"Top 10\", \"1\": \"Top 1\"})\n",
    "    # fig = px.histogram(stats, x=\"best_score\", color=\"Top 50\", nbins=50, histnorm=\"percent\")\n",
    "    # separate correct and incorrect\n",
    "\n",
    "    # fig = px.histogram(stats, x=\"best_score\", color=\"Top 5\", nbins=25, barmode=\"overlay\")\n",
    "    # update colors to match the bar chart\n",
    "    # update colors of the legend \"Found\"\n",
    "    # custom_colors = {\n",
    "    #     \"True\": \"#8C96E9\",  # Light purple/blue\n",
    "    #     \"False\": \"#FFA07A\"  # Soft coral/pink\n",
    "    # }\n",
    "\n",
    "    fig = px.histogram(\n",
    "        stats,\n",
    "        x=prop_to_plot,\n",
    "        color=color_column,\n",
    "        nbins=30,\n",
    "        barmode=\"overlay\",\n",
    "        histnorm=stat,\n",
    "        color_discrete_map={\n",
    "            True: \"rgb(152, 86, 86)\",  # Previously used for \"ref. top 5\"\n",
    "            False: \"rgb(152, 146, 186)\",  # Previously used for \"top 1\"\n",
    "        },\n",
    "        # color_discrete_map=custom_colors,\n",
    "    )\n",
    "    # add side histograms with size di\n",
    "    # color name\n",
    "    xaxis_titles = {\n",
    "            \"best_score\": \"cosine similarity\",\n",
    "            \"mol_size\": \"molecule size\",\n",
    "            \"max_initial_population\": \"max initial population similarity\",\n",
    "            \"molecular_complexity\": \"Bertz complexity\"\n",
    "        }\n",
    "    fig.update_xaxes(\n",
    "        title_text=xaxis_titles.get(prop_to_plot, prop_to_plot),\n",
    "        showgrid=False,\n",
    "        zeroline=False,\n",
    "        showline=False,\n",
    "        ticks=\"outside\",\n",
    "        tickwidth=1,\n",
    "        tickcolor='rgb(120, 120, 120)',\n",
    "        ticklen=5\n",
    "    )\n",
    "    # Configure y-axis\n",
    "    fig.update_yaxes(\n",
    "        title_text='count' if stat is None else stat,\n",
    "        showgrid=False,\n",
    "        gridwidth=1,\n",
    "        gridcolor='rgba(173, 216, 230, 0.3)',\n",
    "        zeroline=False,\n",
    "        showline=False,\n",
    "        ticks=\"outside\",\n",
    "        tickwidth=1,\n",
    "        tickcolor='rgb(120, 120, 120)',\n",
    "        ticklen=5\n",
    "    )\n",
    "    # x axis title\n",
    "    if prop_to_plot == \"best_score\":\n",
    "        xaxis_title = \"cosine similarity\"\n",
    "    elif prop_to_plot == \"mol_size\":\n",
    "        xaxis_title = \"molecule size\"\n",
    "    elif prop_to_plot == \"max_initial_population\":\n",
    "        xaxis_title = \"max initial population similarity\"\n",
    "    elif prop_to_plot == \"molecular_complexity\":\n",
    "        xaxis_title = \"Bertz complexity\"\n",
    "        # log average\n",
    "        logger.info(stats[\"molecular_complexity\"].mean())\n",
    "    fig.update_xaxes(title_text=xaxis_title)\n",
    "    # cmu sans serif\n",
    "    fig.update_layout(font_family=\"CMU Sans Serif\")\n",
    "    fig.update_traces(marker={\"line\": {\"width\": 0.2, \"color\": \"DarkSlateGrey\"}})\n",
    "    fig.update_traces(opacity=1)\n",
    "    # range 0.5 to 1\n",
    "    if prop_to_plot == \"best_score\":\n",
    "        fig.update_xaxes(range=[0.5, 1], tickvals=np.arange(0.6, 1.11, 0.1))\n",
    "        fig.add_vline(x=1, line_dash=\"dot\", annotation_text=\"perfect similarity\", annotation_position=\"bottom right\")\n",
    "    # fig.update_xaxes(showline=True, linecolor=\"black\", linewidth=0.4)\n",
    "    if prop_to_plot == \"mol_size\":\n",
    "        fig.update_xaxes(range=[4, 36])\n",
    "    # perfect similarity line\n",
    "    # rotate vlinae text\n",
    "    fig.update_annotations(textangle=90)\n",
    "    # white background\n",
    "    fig.update_layout(plot_bgcolor=\"white\")\n",
    "    # width and height\n",
    "    fig.update_layout(width=250 * 1.6180339887, height=250)\n",
    "    # tight layout\n",
    "    fig.update_layout(margin={\"l\": 0, \"r\": 0, \"t\": 0, \"b\": 0})\n",
    "    fig.write_image(f\"figures/correct_vs_not_correct_{prop_to_plot}_{color_column}.pdf\", scale=5)\n",
    "    fig.show()\n",
    "\n",
    "\n",
    "plot_distr_of_scores_when_correct_vs_not_correct(\"mol_size\", color_column=\"Top 1\")\n",
    "plot_distr_of_scores_when_correct_vs_not_correct(\"mol_size\", color_column=\"Top 5\")\n",
    "plot_distr_of_scores_when_correct_vs_not_correct(\"mol_size\", color_column=\"Top 10\")\n",
    "plot_distr_of_scores_when_correct_vs_not_correct(\"mol_size\", color_column=\"Found\")\n",
    "\n",
    "plot_distr_of_scores_when_correct_vs_not_correct(\"molecular_complexity\", color_column=\"Top 1\")  # , stat=\"percent\")\n",
    "plot_distr_of_scores_when_correct_vs_not_correct(\"molecular_complexity\", color_column=\"Top 5\")  # , stat=\"percent\")\n",
    "plot_distr_of_scores_when_correct_vs_not_correct(\"molecular_complexity\", color_column=\"Top 10\")  # , stat=\"percent\")\n",
    "plot_distr_of_scores_when_correct_vs_not_correct(\"molecular_complexity\", color_column=\"Found\")  # , stat=\"percent\")\n",
    "\n",
    "plot_distr_of_scores_when_correct_vs_not_correct(\"best_score\", color_column=\"Top 1\")  # , stat=\"percent\")\n",
    "plot_distr_of_scores_when_correct_vs_not_correct(\"best_score\", color_column=\"Top 5\")  # , stat=\"percent\")\n",
    "plot_distr_of_scores_when_correct_vs_not_correct(\"best_score\", color_column=\"Top 10\")  # , stat=\"percent\")\n",
    "plot_distr_of_scores_when_correct_vs_not_correct(\"best_score\", color_column=\"Found\")  # , stat=\"percent\")\n",
    "\n",
    "plot_distr_of_scores_when_correct_vs_not_correct(\"max_initial_population\", color_column=\"Top 1\")  # ,stat=\"percent\")\n",
    "plot_distr_of_scores_when_correct_vs_not_correct(\"max_initial_population\", color_column=\"Top 5\")  # ,stat=\"percent\")\n",
    "plot_distr_of_scores_when_correct_vs_not_correct(\"max_initial_population\", color_column=\"Top 10\")  # ,stat=\"percent\")\n",
    "plot_distr_of_scores_when_correct_vs_not_correct(\"max_initial_population\", color_column=\"Found\")  # ,stat=\"percent\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "from sklearn.calibration import calibration_curve\n",
    "\n",
    "\n",
    "def plot_score_calibration(results_path=\"all_stats.csv\", n_bins=10, top_k=5, strategy=\"uniform\"):\n",
    "    \"\"\"\n",
    "    Creates a calibration plot for best scores showing the relationship between\n",
    "    predicted similarity scores and actual success rates.\n",
    "\n",
    "    Args:\n",
    "        results_path (str): Path to the CSV file with results\n",
    "        n_bins (int): Number of bins for calibration curve\n",
    "    \"\"\"\n",
    "    # Read and preprocess data\n",
    "    stats = pd.read_csv(results_path)\n",
    "    stats = stats[stats[\"best_score\"] != 0]\n",
    "\n",
    "    # Calculate calibration curve\n",
    "    # Using Top 5 as the binary outcome and best_score as the prediction\n",
    "    y_true = stats[f\"{top_k}\"].astype(bool)\n",
    "    y_pred = stats[\"best_score\"]\n",
    "    # scale to 0-1\n",
    "    y_pred = (y_pred - y_pred.min()) / (y_pred.max() - y_pred.min())\n",
    "    prob_true, prob_pred = calibration_curve(y_true, y_pred, n_bins=n_bins, strategy=strategy)\n",
    "\n",
    "    # Create the calibtion plot\n",
    "    fig = go.Figure()\n",
    "\n",
    "    # Add perfect calibration line\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=[0, 1], y=[0, 1], mode=\"lines\", name=\"perfect calibration\", line={\"dash\": \"dash\", \"color\": \"gray\"}, showlegend=True\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Add calibration curve\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=prob_pred,\n",
    "            y=prob_true,\n",
    "            mode=\"lines+markers\",\n",
    "            name=\"pipeline calibration\",\n",
    "            line={\"color\": \"rgb(152, 86, 86)\"},\n",
    "            marker={\"size\": 8, \"color\": \"rgb(152, 86, 86)\", \"line\": {\"width\": 1, \"color\": \"DarkSlateGrey\"}},\n",
    "            showlegend=True,\n",
    "        )\n",
    "    )\n",
    "    sizing = 250\n",
    "    # Update layout\n",
    "    fig.update_layout(\n",
    "        font_family=\"CMU Sans Serif\",\n",
    "        plot_bgcolor=\"white\",\n",
    "        width=sizing * 1.6180339887,\n",
    "        height=sizing,\n",
    "        margin={\"l\": 0, \"r\": 0, \"t\": 0, \"b\": 0},\n",
    "        xaxis={\n",
    "            \"title\": \"scaled cosine similarity\",\n",
    "            \"range\": [0, 1],\n",
    "            \"tickvals\": np.arange(0, 1.1, 0.2),\n",
    "        },\n",
    "        yaxis={\n",
    "            \"title\": f\"top-{top_k} accuracy\",\n",
    "            \"range\": [0, 1],\n",
    "            \"tickvals\": np.arange(0, 1.1, 0.2),\n",
    "        },\n",
    "    )\n",
    "    fig.update_yaxes(\n",
    "        showgrid=False,\n",
    "        gridcolor=\"rgba(173, 216, 230, 0.3)\",\n",
    "        zeroline=False,\n",
    "        showline=False,\n",
    "        ticks=\"outside\",\n",
    "        tickwidth=1,\n",
    "        tickcolor=\"rgb(120, 120, 120)\",\n",
    "        ticklen=5,\n",
    "    )\n",
    "    fig.update_xaxes(\n",
    "        showgrid=False,\n",
    "        gridcolor=\"rgba(173, 216, 230, 0.3)\",\n",
    "        zeroline=False,\n",
    "        showline=False,\n",
    "        ticks=\"outside\",\n",
    "        tickwidth=1,\n",
    "        tickcolor=\"rgb(120, 120, 120)\",\n",
    "        ticklen=5,\n",
    "    )\n",
    "\n",
    "    # rotate x-ticks\n",
    "    # fig.update_xaxes(tickangle=60)\n",
    "    # Add histogram of predictions as small bars at bottom\n",
    "    hist, bins = np.histogram(y_pred, bins=n_bins, range=(0, 1))\n",
    "    hist = hist / hist.max() * 0.5  # Normalize to 10% of plot height\n",
    "\n",
    "    # compute the accuracy of the calibration\n",
    "    # accuracy = np.abs(prob_true - prob_pred).mean()\n",
    "    # add text to the plot\n",
    "    # fig.add_annotation(\n",
    "    #     x=0.5,\n",
    "    #     y=0.1,\n",
    "    #     text=f\"Calibration accuracy: {accuracy:.3f}\",\n",
    "    #     showarrow=False,\n",
    "    #     font={\"size\": 12, \"color\": \"black\"},\n",
    "    # )\n",
    "    fig.update_layout(\n",
    "        template=\"plotly_white\",\n",
    "        width=sizing * 1.618,\n",
    "        height=sizing,\n",
    "        margin={\"l\": 40, \"r\": 20, \"t\": 20, \"b\": 40},\n",
    "        plot_bgcolor=\"white\",\n",
    "        font={\"color\": \"rgb(120, 120, 120)\"},\n",
    "        bargap=0.15,\n",
    "        bargroupgap=0.03,\n",
    "        shapes=[\n",
    "            # Add x-axis line\n",
    "            {\n",
    "                \"type\": \"line\",\n",
    "                \"xref\": \"paper\",\n",
    "                \"yref\": \"y\",\n",
    "                \"x0\": 0,\n",
    "                \"x1\": 1,\n",
    "                \"y0\": 0,\n",
    "                \"y1\": 0,  # Position below the bottom bar\n",
    "                \"line\": {\"color\": \"rgb(120, 120, 120)\", \"width\": 1},\n",
    "            },\n",
    "            # Add y-axis line\n",
    "            {\n",
    "                \"type\": \"line\",\n",
    "                \"xref\": \"x\",\n",
    "                \"yref\": \"paper\",\n",
    "                \"x0\": 0,\n",
    "                \"y0\": 0,\n",
    "                \"x1\": 0,\n",
    "                \"y1\": 1,\n",
    "                \"line\": {\"color\": \"rgb(120, 120, 120)\", \"width\": 1},\n",
    "            },\n",
    "        ],\n",
    "    )\n",
    "    fig.add_trace(\n",
    "        go.Bar(\n",
    "            x=bins[:-1] + np.diff(bins) / 2,\n",
    "            y=hist,\n",
    "            marker_color=\"rgba(152, 86, 86, 0.3)\",\n",
    "            name=\"score distribution\",\n",
    "            width=np.diff(bins)[0],\n",
    "            hoverinfo=\"skip\",\n",
    "        )\n",
    "    )\n",
    "    # change font of all text\n",
    "    # Save and display\n",
    "    fig.write_image(f\"figures/best_score_calibration_{strategy}.pdf\", scale=5)\n",
    "    fig.show()\n",
    "\n",
    "    # Print some statistics\n",
    "    print(f\"Number of samples: {len(stats)}\")\n",
    "    print(f\"Average prediction: {y_pred.mean():.3f}\")\n",
    "    print(f\"Success rate: {y_true.mean():.3f}\")\n",
    "\n",
    "\n",
    "# Usage\n",
    "plot_score_calibration(top_k=1, strategy=\"uniform\", n_bins=11)\n",
    "plot_score_calibration(top_k=1, strategy=\"quantile\", n_bins=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "stats_999 = pd.read_csv(\"all_stats.csv\")\n",
    "# Create the DataFrame\n",
    "molsize_df = pd.DataFrame(\n",
    "    {\n",
    "        \"molecule_size\": [\n",
    "            stats_999[\"mol_size\"],\n",
    "        ],\n",
    "    }\n",
    ")\n",
    "\n",
    "# Create a Plotly figure with the same color scheme\n",
    "fig = go.Figure()\n",
    "\n",
    "# Colors inspired by seaborn for a more scientific look\n",
    "# colors\n",
    "\n",
    "# Adding traces for each seed's molecule size distribution as histograms\n",
    "# update size of the plot\n",
    "fig.update_layout(width=200 * 1.6180339887, height=200)\n",
    "# kde curve\n",
    "fig.add_trace(\n",
    "    go.Histogram(\n",
    "        x=molsize_df[\"molecule_size\"][0],\n",
    "        histnorm=\"probability\",\n",
    "        name=f\"Seed {444}\",\n",
    "        opacity=1,\n",
    "        # marker_color=colors[-2],\n",
    "        nbinsx=30,\n",
    "    )\n",
    ")\n",
    "# change color of the bars\n",
    "fig.update_traces(marker_color=\"rgb(152, 86, 86)\")\n",
    "# change font\n",
    "fig.update_layout(font_family=\"CMU Sans Serif\")\n",
    "# opacity of the bars\n",
    "fig.update_traces(opacity=0.6)\n",
    "fig.update_traces(marker={\"line\": {\"width\": 0.4, \"color\": \"DarkSlateGrey\"}})\n",
    "# Update layout for the plot\n",
    "fig.update_layout(\n",
    "    title=\"molecule size distribution\",\n",
    "    xaxis_title=\"number of atoms\",\n",
    "    yaxis_title=\"percentage of molecules\",\n",
    "    barmode=\"overlay\",\n",
    "    plot_bgcolor=\"white\",\n",
    "    legend={\"title\": \"Seeds\"},\n",
    "    font={\"family\": \"Arial\", \"size\": 12},\n",
    "    margin={\"l\": 0, \"r\": 0, \"t\": 0, \"b\": 0},\n",
    ")\n",
    "fig.write_image(\"figures/molecule_size_distribution.pdf\", scale=5)\n",
    "# Show the plot\n",
    "fig.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chembench",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
